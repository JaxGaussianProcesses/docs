{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 07:24:12.432916: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "import gpjax as gpx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "from jax.config import config\n",
    "import matplotlib.pyplot as plt\n",
    "import distrax as dx\n",
    "\n",
    "key = jr.PRNGKey(123)\n",
    "config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97098371",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "gram() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11530/3536607203.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxlims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrue_kxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_kernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mtrue_L\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_kxx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriangular_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mlatent_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormalTri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_L\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: gram() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "n_data = 100\n",
    "n_realisations = 5\n",
    "noise_limits = (0.3, 0.5)\n",
    "xlims = (-5, 5)\n",
    "jitter = 1e-6\n",
    "n_inducing = 20\n",
    "\n",
    "true_kernel = gpx.kernels.Matern32()\n",
    "true_params = gpx.initialise(true_kernel, key)\n",
    "\n",
    "X = jnp.linspace(*xlims, n_data).reshape(-1, 1)\n",
    "true_kxx = true_kernel.gram(true_kernel, true_params.params, X) + jnp.eye(n_data) * jitter\n",
    "true_L = true_kxx.triangular_lower()\n",
    "latent_dist = dx.MultivariateNormalTri(jnp.zeros(n_data), true_L)\n",
    "group_y = latent_dist.sample(seed=key, sample_shape=(1,)).T\n",
    "\n",
    "\n",
    "noise_terms = dx.Uniform(*noise_limits).sample(seed= key, sample_shape=(n_realisations, ))\n",
    "\n",
    "# def add_sig(i):\n",
    "#     X = jnp.linspace(*xlims, n_data).reshape(-1, 1)\n",
    "#     group_y = tfp.distributions.MultivariateNormalTriL(np.zeros(n_data), tf.linalg.cholesky(Kxx)).sample(seed=tfp_seed + 10 * i)\n",
    "#     sample_y = group_y.numpy()\n",
    "#     return sample_y\n",
    "\n",
    "realisations = []\n",
    "individuals_ys = []\n",
    "for idx, (noise, skey) in enumerate(zip(noise_terms, jr.split(key, n_realisations))):\n",
    "    # Split the key\n",
    "    noise_vector = dx.Normal(0, noise).sample(seed=skey, sample_shape=group_y.shape)\n",
    "    y = group_y + noise_vector\n",
    "    individuals_ys.append(y)\n",
    "    realisations.append(gpx.Dataset(X=X, y=y))\n",
    "    plt.plot(X, y, color='tab:blue')\n",
    "plt.plot(X, group_y, color='tab:red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e60296d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inducing_points = jnp.linspace(*xlims, n_inducing).reshape(-1, 1)\n",
    "\n",
    "individual_priors = [gpx.Prior(kernel = gpx.kernels.RBF()) for _ in range(n_realisations)]\n",
    "group_prior = gpx.Prior(kernel = gpx.kernels.RBF())\n",
    "likelihood = gpx.Gaussian(num_datapoints=n_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8565aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp \n",
    "from jaxtyping import Float, Array\n",
    "from chex import PRNGKey as PRNGKeyType, dataclass\n",
    "from gpjax.utils import concat_dictionaries\n",
    "import optax as ox\n",
    "from itertools import product\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SHGP:\n",
    "    individual_priors: tp.List[gpx.Prior]\n",
    "    group_prior: gpx.Prior\n",
    "    likelihood: gpx.likelihoods.AbstractLikelihood\n",
    "    inducing_inputs: Float[Array, \"M D\"]\n",
    "    name: str = \"Sparse Hierarchical GP\"\n",
    "    diag: tp.Optional[bool] = False\n",
    "    \n",
    "    def _initialise_params(self, key: PRNGKeyType) -> tp.Dict:\n",
    "        params = {}\n",
    "        params[\"kernel\"] = [p._initialise_params(key)['kernel'] for p in self.individual_priors] + [self.group_prior._initialise_params(key)['kernel']]\n",
    "        params['mean_function'] = {}\n",
    "        params = concat_dictionaries(params,             {\n",
    "                \"variational_family\": {\"inducing_inputs\": self.inducing_inputs},\n",
    "                \"likelihood\": {\n",
    "                    \"obs_noise\": self.likelihood._initialise_params(key)[\"obs_noise\"]\n",
    "                },\n",
    "            })\n",
    "        params = jax.tree_map(lambda x: jnp.atleast_2d(x), params)\n",
    "        return params\n",
    "    \n",
    "    def fit_map(self, data: tp.List[gpx.Dataset], optimiser: ox.GradientTransformation, n_iters: int = 1, compile: bool = False, verbose: bool =True, log_rate: int =10):\n",
    "        loss_fns = self._build_objective(key, data, negative=True, compile=compile)\n",
    "        n_losses = jnp.arange(len(loss_fns))\n",
    "        initial_params = gpx.initialise(self, key)\n",
    "        parameters, _, bijectors = initial_params.unpack()\n",
    "\n",
    "        \n",
    "        def objective(params: tp.Dict):\n",
    "            # Evaluate each loss function in the loss_fns list with the params variable and sum the result\n",
    "            # return jax.tree_util.tree_reduce(lambda x, y: x + y, [loss_fn(params) for loss_fn in loss_fns])\n",
    "            vmap_fn = jax.vmap(lambda i, x: jax.lax.switch(i, loss_fns, x))\n",
    "            return jnp.sum(vmap_fn(n_losses, params))\n",
    "        \n",
    "        parameters = gpx.unconstrain(parameters, bijectors)\n",
    "        dict_to_array, array_to_dict = gpx.utils.dict_array_coercion(parameters)\n",
    "        parameters = dict_to_array(parameters)\n",
    "\n",
    "        opt_state = optimiser.init(parameters)\n",
    "        iter_nums = jnp.arange(n_iters)\n",
    "\n",
    "        # Optimisation step\n",
    "        def step(carry, iter_num: int):\n",
    "            parameters, opt_state = carry\n",
    "            loss_val, loss_gradient = jax.value_and_grad(objective)(parameters)\n",
    "            print(loss_gradient)\n",
    "            updates, opt_state = optimiser.update(loss_gradient, opt_state, parameters)\n",
    "            parameters = ox.apply_updates(parameters, updates)\n",
    "            carry = parameters, opt_state\n",
    "            return carry, loss_val\n",
    "\n",
    "\n",
    "        if verbose:\n",
    "            step = gpx.abstractions.progress_bar_scan(n_iters, log_rate)(step)\n",
    "\n",
    "        # Run the optimisation loop\n",
    "        (parameters, _), history = jax.lax.scan(step, (parameters, opt_state), iter_nums)\n",
    "\n",
    "        # Tranform final params to constrained space\n",
    "        parameters = gpx.constrain(parameters, bijectors)\n",
    "        return gpx.abstractions.InferenceState(params=parameters, history=history)\n",
    "    \n",
    "        \n",
    "    def fit(self, data: tp.List[gpx.Dataset], optimiser: ox.GradientTransformation, n_iters: int = 1, compile: bool = False, verbose: bool =True, log_rate: int =10):\n",
    "        loss_fns = self._build_objective(key, data, negative=True, compile=compile)\n",
    "        initial_params = gpx.initialise(self, key)\n",
    "        parameters, _, bijectors = initial_params.unpack()\n",
    "        \n",
    "        @jax.jit\n",
    "        def objective(params: tp.Dict):\n",
    "            return jnp.sum(jax.Array([l(params) for l in loss_fns]))\n",
    "        \n",
    "        parameters = gpx.unconstrain(parameters, bijectors)\n",
    "        \n",
    "        opt_state = optimiser.init(parameters)\n",
    "        iter_nums = jnp.arange(n_iters)\n",
    "        \n",
    "        # Optimisation step\n",
    "        def step(carry, iter_num: int):\n",
    "            parameters, opt_state = carry\n",
    "            loss_val, loss_gradient = jax.value_and_grad(objective)(parameters)\n",
    "            updates, opt_state = optimiser.update(loss_gradient, opt_state, parameters)\n",
    "            parameters = ox.apply_updates(parameters, updates)\n",
    "            carry = parameters, opt_state\n",
    "            return carry, loss_val\n",
    "\n",
    "\n",
    "        if verbose:\n",
    "            step = gpx.abstractions.progress_bar_scan(n_iters, log_rate)(step)\n",
    "\n",
    "        # Run the optimisation loop\n",
    "        (parameters, _), history = jax.lax.scan(step, (parameters, opt_state), iter_nums)\n",
    "\n",
    "        # Tranform final params to constrained space\n",
    "        parameters = gpx.constrain(parameters, bijectors)\n",
    "        return gpx.abstractions.InferenceState(params=parameters, history=history)\n",
    "    \n",
    "    def _build_objective(self, key:PRNGKeyType, datasets: tp.List[gpx.Dataset], negative: bool, compile: bool) -> tp.Callable:\n",
    "        n_realisations = len(datasets)\n",
    "        idxs = list(product(range(n_realisations), range(n_realisations)))\n",
    "        losses = []\n",
    "        params = []\n",
    "\n",
    "        param_state = self._initialise_params(key)\n",
    "        \n",
    "        for idx in idxs:\n",
    "            # For diagonal entries the group prior is summed with the relevant individual prior\n",
    "            kernel_list = [gpx.kernels.RBF()] * (n_realisations+1)\n",
    "            # if idx[0] == idx[1]:\n",
    "            #     # Due to the parameter's structure, it is important that the group kernel is last.\n",
    "            #     ik1 = self.individual_priors[idx[0]].kernel\n",
    "            #     gk = self.group_prior.kernel\n",
    "            #     kernel = ik1 + gk\n",
    "            # else:\n",
    "            #     kernel = self.group_prior.kernel\n",
    "            kernel_list[idx[0]] = self.individual_priors[idx[0]].kernel\n",
    "            if idx[0] == idx[1]:\n",
    "                # Due to the parameter's structure, it is important that the group kernel is last.\n",
    "                kernel_list[-1] = self.group_prior.kernel                \n",
    "            \n",
    "            kernel = kernel_list[0]\n",
    "            for k in kernel_list[1:]:\n",
    "                kernel += k\n",
    "\n",
    "            prior = gpx.Prior(kernel=kernel)\n",
    "            posterior = prior * self.likelihood\n",
    "            q = gpx.CollapsedVariationalGaussian(prior=prior, likelihood=self.likelihood, inducing_inputs=self.inducing_inputs)\n",
    "            sgpr = gpx.CollapsedVI(posterior=posterior, variational_family=q)\n",
    "            \n",
    "            param_state = gpx.initialise(sgpr, key)\n",
    "            \n",
    "            D = datasets[idx[0]]\n",
    "            temp_param_copy = deepcopy(param_state)\n",
    "            if idx[0] == idx[1]:\n",
    "                for temp_idx, kernel_term in enumerate(temp_param_copy.trainables['kernel'][:-1]):\n",
    "                    if temp_idx != idx[0]:\n",
    "                        for kernel_parameter_status, _ in kernel_term.items():\n",
    "                            kernel_term[kernel_parameter_status] = False\n",
    "                        temp_param_copy.params['kernel'][temp_idx]['variance'] = jax.Array([0.])\n",
    "            else:\n",
    "                for temp_idx, kernel_term in enumerate(temp_param_copy.trainables['kernel']):\n",
    "                    if temp_idx != idx[0]:\n",
    "                        for kernel_parameter_status, _ in kernel_term.items():\n",
    "                            kernel_term[kernel_parameter_status] = False \n",
    "                        temp_param_copy.params['kernel'][temp_idx]['variance'] = jax.Array([0.])\n",
    "                        \n",
    "            param_state.trainables = temp_param_copy.trainables\n",
    "            dict_to_array, array_to_dict = gpx.utils.dict_array_coercion(param_state.params)\n",
    "\n",
    "            def loss_fn(params: tp.Dict) -> Float[Array, \"\"]:\n",
    "                _, trainables, _ = param_state.unpack()\n",
    "                params = array_to_dict(params)\n",
    "                params = gpx.parameters.trainable_params(params, trainables)\n",
    "                return sgpr.elbo(D, negative=negative)(params)\n",
    "            if compile:\n",
    "                loss_fn = jax.jit(loss_fn)\n",
    "            losses.append(loss_fn)\n",
    "        return losses\n",
    "shgp = SHGP(individual_priors=individual_priors, group_prior=group_prior, likelihood=likelihood, inducing_inputs=inducing_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f94627c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fns = shgp._build_objective(key, realisations, negative=True, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b50e7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "{'kernel': [{'lengthscale': False, 'variance': False}, {'lengthscale': False, 'variance': False}, {'lengthscale': False, 'variance': False}, {'lengthscale': False, 'variance': False}, {'lengthscale': True, 'variance': True}, {'lengthscale': True, 'variance': True}], 'likelihood': {'obs_noise': True}, 'mean_function': {}, 'variational_family': {'inducing_inputs': True}}\n",
      "--------------------------------------------------\n",
      "{'kernel': [{'lengthscale': DeviceArray([[1.]], dtype=float64), 'variance': DeviceArray([[1.]], dtype=float64)}, {'lengthscale': DeviceArray([[1.]], dtype=float64), 'variance': DeviceArray([[1.]], dtype=float64)}, {'lengthscale': DeviceArray([[1.]], dtype=float64), 'variance': DeviceArray([[1.]], dtype=float64)}, {'lengthscale': DeviceArray([[1.]], dtype=float64), 'variance': DeviceArray([[1.]], dtype=float64)}, {'lengthscale': DeviceArray([[1.]], dtype=float64), 'variance': DeviceArray([[1.]], dtype=float64)}, {'lengthscale': DeviceArray([[1.]], dtype=float64), 'variance': DeviceArray([[1.]], dtype=float64)}], 'likelihood': {'obs_noise': DeviceArray([[1.]], dtype=float64)}, 'mean_function': {}, 'variational_family': {'inducing_inputs': DeviceArray([[-5.        ],\n",
      "             [-4.47368421],\n",
      "             [-3.94736842],\n",
      "             [-3.42105263],\n",
      "             [-2.89473684],\n",
      "             [-2.36842105],\n",
      "             [-1.84210526],\n",
      "             [-1.31578947],\n",
      "             [-0.78947368],\n",
      "             [-0.26315789],\n",
      "             [ 0.26315789],\n",
      "             [ 0.78947368],\n",
      "             [ 1.31578947],\n",
      "             [ 1.84210526],\n",
      "             [ 2.36842105],\n",
      "             [ 2.89473684],\n",
      "             [ 3.42105263],\n",
      "             [ 3.94736842],\n",
      "             [ 4.47368421],\n",
      "             [ 5.        ]], dtype=float64)}}\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Too few leaves for PyTreeDef; expected 14, got 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15625/3843205088.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mparam_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshgp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss_fns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15625/2748190827.py\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python_dev/GPJax/gpjax/utils.py\u001b[0m in \u001b[0;36marray_to_dict\u001b[0;34m(parameter_array)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0marray_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameter_array\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflattened_pytree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict_to_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_to_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gpjax/lib/python3.9/site-packages/jax/_src/tree_util.py\u001b[0m in \u001b[0;36mtree_unflatten\u001b[0;34m(treedef, leaves)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mdescribed\u001b[0m \u001b[0mby\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtreedef\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \"\"\"\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtreedef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtree_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Too few leaves for PyTreeDef; expected 14, got 4"
     ]
    }
   ],
   "source": [
    "param_state = gpx.initialise(shgp, key)\n",
    "loss_fns[1](param_state.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f741f0cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dffccf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "vmap got inconsistent sizes for array axes to be mapped:\nthe tree of axis sizes is:\n(25, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 20])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15625/3205278089.py\u001b[0m in \u001b[0;36mfit_map\u001b[0;34m(self, data, optimiser, n_iters, compile, verbose, log_rate)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;31m# Run the optimisation loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_nums\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Tranform final params to constrained space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "\u001b[0;32m~/python_dev/GPJax/gpjax/abstractions.py\u001b[0m in \u001b[0;36mwrapper_progress_bar\u001b[0;34m(carry, x)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;31m# Compute iteration step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;31m# Get loss value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15625/3205278089.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(carry, iter_num)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcarry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_num\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcarry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mloss_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_gradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mupdates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15625/3205278089.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# return jax.tree_util.tree_reduce(lambda x, y: x + y, [loss_fn(params) for loss_fn in loss_fns])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mvmap_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconstrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbijectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/gpjax/lib/python3.9/site-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_mapped_axis_size\u001b[0;34m(tree, vals, dims, name, kws)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0msizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"the tree of axis sizes is:\\n{sizes}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: vmap got inconsistent sizes for array axes to be mapped:\nthe tree of axis sizes is:\n(25, [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 20])"
     ]
    }
   ],
   "source": [
    "%time shgp.fit_map(realisations, optimiser=ox.adam(learning_rate=0.01), compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5dd7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a7790c0a294e9a98c55a9911727690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54 s, sys: 426 ms, total: 54.4 s\n",
      "Wall time: 52.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "InferenceState(params={'kernel': [{'lengthscale': DeviceArray([[1.]], dtype=float64), 'variance': DeviceArray([[1.]], dtype=float64)}, {'lengthscale': DeviceArray([[1.]], dtype=float64), 'variance': DeviceArray([[1.]], dtype=float64)}, {'lengthscale': DeviceArray([[1.]], dtype=float64), 'variance': DeviceArray([[1.]], dtype=float64)}, {'lengthscale': DeviceArray([[1.]], dtype=float64), 'variance': DeviceArray([[1.]], dtype=float64)}, {'lengthscale': DeviceArray([[1.00633282]], dtype=float64), 'variance': DeviceArray([[0.99369043]], dtype=float64)}, {'lengthscale': DeviceArray([[1.00633282]], dtype=float64), 'variance': DeviceArray([[0.99369043]], dtype=float64)}], 'likelihood': {'obs_noise': DeviceArray([[0.99369043]], dtype=float64)}, 'mean_function': {}, 'variational_family': {'inducing_inputs': DeviceArray([[-4.99      ],\n",
       "             [-4.48368421],\n",
       "             [-3.95736842],\n",
       "             [-3.41105263],\n",
       "             [-2.90473684],\n",
       "             [-2.35842105],\n",
       "             [-1.83210526],\n",
       "             [-1.30578947],\n",
       "             [-0.79947368],\n",
       "             [-0.27315789],\n",
       "             [ 0.25315789],\n",
       "             [ 0.77947368],\n",
       "             [ 1.30578947],\n",
       "             [ 1.83210526],\n",
       "             [ 2.35842105],\n",
       "             [ 2.88473684],\n",
       "             [ 3.43105263],\n",
       "             [ 3.95736842],\n",
       "             [ 4.48368421],\n",
       "             [ 4.99      ]], dtype=float64)}}, history=DeviceArray([2643.10526084], dtype=float64))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time shgp.fit(realisations, optimiser=ox.adam(learning_rate=0.01), compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a79e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = shgp.fit(realisations, optimiser=ox.adam(learning_rate=0.01), n_iters=1, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac65244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(2467.40857979, dtype=float64)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = gpx.initialise(shgp, key)\n",
    "jnp.sum(jax.Array([l(params) for l in loss_fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16326b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseCovarianceOperator(matrix=DeviceArray([[0., 0., 0., ..., 0., 0., 0.],\n",
       "             [0., 0., 0., ..., 0., 0., 0.],\n",
       "             [0., 0., 0., ..., 0., 0., 0.],\n",
       "             ...,\n",
       "             [0., 0., 0., ..., 0., 0., 0.],\n",
       "             [0., 0., 0., ..., 0., 0., 0.],\n",
       "             [0., 0., 0., ..., 0., 0., 0.]], dtype=float64), name='Dense covariance operator')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wparams = gpx.kernels.RBF()._initialise_params(key)\n",
    "wparams['variance'] = jax.Array([0.])\n",
    "gpx.kernels.RBF().gram(gpx.kernels.RBF(), wparams, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163155b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _subset_param_state(params: gpx.parameters.ParameterState, idx: int, group: bool):\n",
    "    # Remove all the parameters except for the one at idx\n",
    "    params.params['individuals'] = params.params['individuals'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e1a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, params = shgp.build_objective(datasets=realisations, negative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1fe117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': [{'lengthscale': True, 'variance': True},\n",
       "  {'lengthscale': True, 'variance': True},\n",
       "  {'lengthscale': True, 'variance': True},\n",
       "  {'lengthscale': True, 'variance': True},\n",
       "  {'lengthscale': True, 'variance': True}],\n",
       " 'likelihood': {'obs_noise': True},\n",
       " 'variational_family': {'inducing_inputs': True}}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpx.initialise(shgp, key).trainables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a143da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'group': {'kernel': {'lengthscale': DeviceArray([1.], dtype=float64),\n",
       "   'variance': DeviceArray([1.], dtype=float64)},\n",
       "  'mean_function': {}},\n",
       " 'individuals': [{'kernel': {'lengthscale': DeviceArray([1.], dtype=float64),\n",
       "    'variance': DeviceArray([1.], dtype=float64)},\n",
       "   'mean_function': {}},\n",
       "  {'kernel': {'lengthscale': DeviceArray([1.], dtype=float64),\n",
       "    'variance': DeviceArray([1.], dtype=float64)},\n",
       "   'mean_function': {}},\n",
       "  {'kernel': {'lengthscale': DeviceArray([1.], dtype=float64),\n",
       "    'variance': DeviceArray([1.], dtype=float64)},\n",
       "   'mean_function': {}},\n",
       "  {'kernel': {'lengthscale': DeviceArray([1.], dtype=float64),\n",
       "    'variance': DeviceArray([1.], dtype=float64)},\n",
       "   'mean_function': {}}],\n",
       " 'variational_family': {'inducing_inputs': DeviceArray([[-5.        ],\n",
       "               [-4.58333333],\n",
       "               [-4.16666667],\n",
       "               [-3.75      ],\n",
       "               [-3.33333333],\n",
       "               [-2.91666667],\n",
       "               [-2.5       ],\n",
       "               [-2.08333333],\n",
       "               [-1.66666667],\n",
       "               [-1.25      ],\n",
       "               [-0.83333333],\n",
       "               [-0.41666667],\n",
       "               [ 0.        ],\n",
       "               [ 0.41666667],\n",
       "               [ 0.83333333],\n",
       "               [ 1.25      ],\n",
       "               [ 1.66666667],\n",
       "               [ 2.08333333],\n",
       "               [ 2.5       ],\n",
       "               [ 2.91666667],\n",
       "               [ 3.33333333],\n",
       "               [ 3.75      ],\n",
       "               [ 4.16666667],\n",
       "               [ 4.58333333],\n",
       "               [ 5.        ]], dtype=float64)},\n",
       " 'likelihood': {'obs_noise': DeviceArray([1.], dtype=float64)}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shgp._initialise_params(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2168ec7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'group': {'kernel': {'lengthscale': DeviceArray([1.], dtype=float64),\n",
       "   'variance': DeviceArray([1.], dtype=float64)},\n",
       "  'mean_function': {}},\n",
       " 'individuals': [{'kernel': {'lengthscale': DeviceArray([1.], dtype=float64),\n",
       "    'variance': DeviceArray([1.], dtype=float64)},\n",
       "   'mean_function': {}},\n",
       "  {'kernel': {'lengthscale': DeviceArray([1.], dtype=float64),\n",
       "    'variance': DeviceArray([1.], dtype=float64)},\n",
       "   'mean_function': {}},\n",
       "  {'kernel': {'lengthscale': DeviceArray([1.], dtype=float64),\n",
       "    'variance': DeviceArray([1.], dtype=float64)},\n",
       "   'mean_function': {}},\n",
       "  {'kernel': {'lengthscale': DeviceArray([1.], dtype=float64),\n",
       "    'variance': DeviceArray([1.], dtype=float64)},\n",
       "   'mean_function': {}}],\n",
       " 'variational_family': {'inducing_inputs': DeviceArray([[-5.        ],\n",
       "               [-4.58333333],\n",
       "               [-4.16666667],\n",
       "               [-3.75      ],\n",
       "               [-3.33333333],\n",
       "               [-2.91666667],\n",
       "               [-2.5       ],\n",
       "               [-2.08333333],\n",
       "               [-1.66666667],\n",
       "               [-1.25      ],\n",
       "               [-0.83333333],\n",
       "               [-0.41666667],\n",
       "               [ 0.        ],\n",
       "               [ 0.41666667],\n",
       "               [ 0.83333333],\n",
       "               [ 1.25      ],\n",
       "               [ 1.66666667],\n",
       "               [ 2.08333333],\n",
       "               [ 2.5       ],\n",
       "               [ 2.91666667],\n",
       "               [ 3.33333333],\n",
       "               [ 3.75      ],\n",
       "               [ 4.16666667],\n",
       "               [ 4.58333333],\n",
       "               [ 5.        ]], dtype=float64)},\n",
       " 'likelihood': {'obs_noise': DeviceArray([1.], dtype=float64)}}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = ox.adam(0.01)\n",
    "shgp.fit(datasets=realisations, key=key, opt=opt).params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93165fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = []\n",
    "\n",
    "for p in individual_priors:\n",
    "    q = gpx.CollapsedVariationalGaussian(prior=p, likelihood=likelihood, inducing_inputs=inducing_points)\n",
    "    qs.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af55ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CollapsedVariationalGaussian(prior=Prior(kernel=Matern32(), mean_function=<gpjax.mean_functions.Zero object at 0x7fee945673a0>, name='GP prior'), likelihood=Gaussian(num_datapoints=50, name='Gaussian'), inducing_inputs=DeviceArray([[-5.        ],\n",
       "              [-4.58333333],\n",
       "              [-4.16666667],\n",
       "              [-3.75      ],\n",
       "              [-3.33333333],\n",
       "              [-2.91666667],\n",
       "              [-2.5       ],\n",
       "              [-2.08333333],\n",
       "              [-1.66666667],\n",
       "              [-1.25      ],\n",
       "              [-0.83333333],\n",
       "              [-0.41666667],\n",
       "              [ 0.        ],\n",
       "              [ 0.41666667],\n",
       "              [ 0.83333333],\n",
       "              [ 1.25      ],\n",
       "              [ 1.66666667],\n",
       "              [ 2.08333333],\n",
       "              [ 2.5       ],\n",
       "              [ 2.91666667],\n",
       "              [ 3.33333333],\n",
       "              [ 3.75      ],\n",
       "              [ 4.16666667],\n",
       "              [ 4.58333333],\n",
       "              [ 5.        ]], dtype=float64), name='Collapsed variational Gaussian', diag=False),\n",
       " CollapsedVariationalGaussian(prior=Prior(kernel=Matern32(), mean_function=<gpjax.mean_functions.Zero object at 0x7fee945673a0>, name='GP prior'), likelihood=Gaussian(num_datapoints=50, name='Gaussian'), inducing_inputs=DeviceArray([[-5.        ],\n",
       "              [-4.58333333],\n",
       "              [-4.16666667],\n",
       "              [-3.75      ],\n",
       "              [-3.33333333],\n",
       "              [-2.91666667],\n",
       "              [-2.5       ],\n",
       "              [-2.08333333],\n",
       "              [-1.66666667],\n",
       "              [-1.25      ],\n",
       "              [-0.83333333],\n",
       "              [-0.41666667],\n",
       "              [ 0.        ],\n",
       "              [ 0.41666667],\n",
       "              [ 0.83333333],\n",
       "              [ 1.25      ],\n",
       "              [ 1.66666667],\n",
       "              [ 2.08333333],\n",
       "              [ 2.5       ],\n",
       "              [ 2.91666667],\n",
       "              [ 3.33333333],\n",
       "              [ 3.75      ],\n",
       "              [ 4.16666667],\n",
       "              [ 4.58333333],\n",
       "              [ 5.        ]], dtype=float64), name='Collapsed variational Gaussian', diag=False),\n",
       " CollapsedVariationalGaussian(prior=Prior(kernel=Matern32(), mean_function=<gpjax.mean_functions.Zero object at 0x7fee945673a0>, name='GP prior'), likelihood=Gaussian(num_datapoints=50, name='Gaussian'), inducing_inputs=DeviceArray([[-5.        ],\n",
       "              [-4.58333333],\n",
       "              [-4.16666667],\n",
       "              [-3.75      ],\n",
       "              [-3.33333333],\n",
       "              [-2.91666667],\n",
       "              [-2.5       ],\n",
       "              [-2.08333333],\n",
       "              [-1.66666667],\n",
       "              [-1.25      ],\n",
       "              [-0.83333333],\n",
       "              [-0.41666667],\n",
       "              [ 0.        ],\n",
       "              [ 0.41666667],\n",
       "              [ 0.83333333],\n",
       "              [ 1.25      ],\n",
       "              [ 1.66666667],\n",
       "              [ 2.08333333],\n",
       "              [ 2.5       ],\n",
       "              [ 2.91666667],\n",
       "              [ 3.33333333],\n",
       "              [ 3.75      ],\n",
       "              [ 4.16666667],\n",
       "              [ 4.58333333],\n",
       "              [ 5.        ]], dtype=float64), name='Collapsed variational Gaussian', diag=False),\n",
       " CollapsedVariationalGaussian(prior=Prior(kernel=Matern32(), mean_function=<gpjax.mean_functions.Zero object at 0x7fee945673a0>, name='GP prior'), likelihood=Gaussian(num_datapoints=50, name='Gaussian'), inducing_inputs=DeviceArray([[-5.        ],\n",
       "              [-4.58333333],\n",
       "              [-4.16666667],\n",
       "              [-3.75      ],\n",
       "              [-3.33333333],\n",
       "              [-2.91666667],\n",
       "              [-2.5       ],\n",
       "              [-2.08333333],\n",
       "              [-1.66666667],\n",
       "              [-1.25      ],\n",
       "              [-0.83333333],\n",
       "              [-0.41666667],\n",
       "              [ 0.        ],\n",
       "              [ 0.41666667],\n",
       "              [ 0.83333333],\n",
       "              [ 1.25      ],\n",
       "              [ 1.66666667],\n",
       "              [ 2.08333333],\n",
       "              [ 2.5       ],\n",
       "              [ 2.91666667],\n",
       "              [ 3.33333333],\n",
       "              [ 3.75      ],\n",
       "              [ 4.16666667],\n",
       "              [ 4.58333333],\n",
       "              [ 5.        ]], dtype=float64), name='Collapsed variational Gaussian', diag=False)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ad975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('gpjax')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "920091140e6b97de16b405af485d142952a229f5dad61a888f46227f5acb94cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
